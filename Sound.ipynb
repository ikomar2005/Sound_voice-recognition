{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa as lr\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.layers import Dense, LSTM, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "SR = 16000 #Sampling frequency\n",
    "\n",
    "def process_audio(aname):\n",
    "  audio, _ = lr.load(aname, sr=SR)\n",
    "\n",
    "  afs = lr.feature.mfcc(audio, \n",
    "                        sr=SR, \n",
    "                        n_mfcc=34, \n",
    "                        n_fft=2048) \n",
    "  afss = np.sum(afs[2:], axis=-1)\n",
    "\n",
    "  # Normalize them\n",
    "  afss = afss / np.max(np.abs(afss))\n",
    "\n",
    "  return afss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence(x, y):\n",
    "  return np.sum((x - y)**2) # Euclidean distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Igor\\Desktop\\phyton\\SOUND\n"
     ]
    }
   ],
   "source": [
    "# Download multiple audio tracks\n",
    "#%cd C:\\Users\\Igor\\Desktop\\phyton\\SOUND\n",
    "woman11 = process_audio(\"Mogilko_1.wav\")\n",
    "woman12 = process_audio(\"Mogilko_2.wav\")\n",
    "woman21 = process_audio(\"Maria_1.wav\")\n",
    "woman22 = process_audio(\"Maria_2.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "same 2.8557765\n",
      "same 0.178615\n",
      "diff 1.9570591\n",
      "diff 1.6290247\n",
      "diff 2.5593805\n",
      "diff 2.1673884\n"
     ]
    }
   ],
   "source": [
    "#Compare proximity coefficients\n",
    "print('same', confidence(woman11, woman12))\n",
    "print('same', confidence(woman21, woman22))\n",
    "print('diff', confidence(woman11, woman21))\n",
    "print('diff', confidence(woman11, woman22))\n",
    "print('diff', confidence(woman12, woman21))\n",
    "print('diff', confidence(woman12, woman22))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_audio(audio):\n",
    "  # We calculate the voice energy for each block in 125 ms\n",
    "  apower = lr.amplitude_to_db(np.abs(lr.stft(audio, n_fft=2048)), ref=np.max)\n",
    "\n",
    "  # We summarize the energy at each frequency, normalize\n",
    "  apsums = np.sum(apower, axis=0)**2\n",
    "  apsums -= np.min(apsums)\n",
    "  apsums /= np.max(apsums)\n",
    "\n",
    "  # We smooth the chart to keep short skips and pauses, to remove sharpness\n",
    "  apsums = np.convolve(apsums, np.ones((9,)), 'same')\n",
    "  # Normalize again\n",
    "  apsums -= np.min(apsums)\n",
    "  apsums /= np.max(apsums)\n",
    "\n",
    "  # Устанавливаем порог в 35% шума над голосом\n",
    "  apsums = np.array(apsums > 0.35, dtype=bool)\n",
    "\n",
    "   # Extend blocks each 125 ms to individual samples (2048 per block)\n",
    "  apsums = np.repeat(apsums, np.ceil(len(audio) / len(apsums)))[:len(audio)]\n",
    "\n",
    "  return audio[apsums] # We filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "SR = 16000 #Sampling frequency\n",
    "LENGTH = 16 #The number of blocks in one pass of the neural network\n",
    "OVERLAP = 8 #The step in the number of blocks between training samples\n",
    "FFT = 1024 # Block Length (64 ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_audio(aname, target=False):\n",
    "  # Download and prepare data\n",
    "  print('loading %s' % aname)\n",
    "  audio, _ = lr.load(aname, sr=SR)\n",
    "  audio = filter_audio(audio) #Remove silence and spaces between words\n",
    "  data = lr.stft(audio, n_fft=FFT).swapaxes(0, 1) #Extract the spectrogram\n",
    "  samples = []\n",
    "\n",
    "  for i in range(0, len(data) - LENGTH, OVERLAP):\n",
    "    samples.append(np.abs(data[i:i + LENGTH])) # Create a training set\n",
    "\n",
    "  results_shape = (len(samples), 1)\n",
    "  results = np.ones(results_shape) if target else np.zeros(results_shape)\n",
    "  return np.array(samples), results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all entries\n",
    "voices = [(\"Mogilko_1.wav\", True),\n",
    "          (\"Mogilko_2.wav\", True),\n",
    "          (\"Mogilko_3.wav\", True),\n",
    "          (\"Maria_1.wav\", False),\n",
    "          (\"Maria_2.wav\", False),\n",
    "          (\"Maria_3.wav\", False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Mogilko_1.wav\n",
      "loading Mogilko_2.wav\n",
      "loading Mogilko_3.wav\n",
      "loading Maria_1.wav\n",
      "loading Maria_2.wav\n",
      "loading Maria_3.wav\n"
     ]
    }
   ],
   "source": [
    "# Combining training samples\n",
    "X, Y = prepare_audio(*voices[0])\n",
    "for voice in voices[1:]:\n",
    "  dx, dy = prepare_audio(*voice)\n",
    "  X = np.concatenate((X, dx), axis=0)\n",
    "  Y = np.concatenate((Y, dy), axis=0)\n",
    "  del dx, dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomly mix all the blocks\n",
    "perm = np.random.permutation(len(X))\n",
    "X = X[perm]\n",
    "Y = Y[perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Create a model\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, return_sequences=True, input_shape=X.shape[1:]))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dense(16))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('hard_sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Train on 2728 samples, validate on 683 samples\n",
      "Epoch 1/15\n",
      "2728/2728 [==============================] - 8s 3ms/step - loss: 0.3709 - acc: 0.8387 - val_loss: 0.5056 - val_acc: 0.7950\n",
      "Epoch 2/15\n",
      "2728/2728 [==============================] - 5s 2ms/step - loss: 0.2088 - acc: 0.9366 - val_loss: 0.1607 - val_acc: 0.9385\n",
      "Epoch 3/15\n",
      "2728/2728 [==============================] - 6s 2ms/step - loss: 0.1780 - acc: 0.9476 - val_loss: 0.3892 - val_acc: 0.9078 - \n",
      "Epoch 4/15\n",
      "2728/2728 [==============================] - 6s 2ms/step - loss: 0.1319 - acc: 0.9626 - val_loss: 0.0936 - val_acc: 0.9663\n",
      "Epoch 5/15\n",
      "2728/2728 [==============================] - 6s 2ms/step - loss: 0.0981 - acc: 0.9721 - val_loss: 0.0628 - val_acc: 0.9751\n",
      "Epoch 6/15\n",
      "2728/2728 [==============================] - 6s 2ms/step - loss: 0.0682 - acc: 0.9762 - val_loss: 0.0788 - val_acc: 0.9766\n",
      "Epoch 7/15\n",
      "2728/2728 [==============================] - 6s 2ms/step - loss: 0.0622 - acc: 0.9802 - val_loss: 0.1038 - val_acc: 0.9575\n",
      "Epoch 8/15\n",
      "2728/2728 [==============================] - 6s 2ms/step - loss: 0.0797 - acc: 0.9751 - val_loss: 0.1463 - val_acc: 0.9531- loss: 0.\n",
      "Epoch 9/15\n",
      "2728/2728 [==============================] - 6s 2ms/step - loss: 0.3454 - acc: 0.8530 - val_loss: 0.2444 - val_acc: 0.9268\n",
      "Epoch 10/15\n",
      "2728/2728 [==============================] - 6s 2ms/step - loss: 0.2177 - acc: 0.9322 - val_loss: 0.2292 - val_acc: 0.9136\n",
      "Epoch 11/15\n",
      "2728/2728 [==============================] - 6s 2ms/step - loss: 0.1268 - acc: 0.9633 - val_loss: 0.0843 - val_acc: 0.9780\n",
      "Epoch 12/15\n",
      "2728/2728 [==============================] - 6s 2ms/step - loss: 0.1490 - acc: 0.9597 - val_loss: 0.7010 - val_acc: 0.5695\n",
      "Epoch 13/15\n",
      "2728/2728 [==============================] - 6s 2ms/step - loss: 0.4405 - acc: 0.8120 - val_loss: 0.7708 - val_acc: 0.6471\n",
      "Epoch 14/15\n",
      "2728/2728 [==============================] - 6s 2ms/step - loss: 0.3146 - acc: 0.9095 - val_loss: 0.2318 - val_acc: 0.9531\n",
      "Epoch 15/15\n",
      "2728/2728 [==============================] - 6s 2ms/step - loss: 0.2003 - acc: 0.9696 - val_loss: 0.1940 - val_acc: 0.9678\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28de84fb6d8>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Compile and train the model\n",
    "model.compile(Adam(lr=0.005), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X, Y, epochs=15, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3411/3411 [==============================] - 2s 524us/step\n",
      "[0.1714822928364135, 0.9821166814474444]\n"
     ]
    }
   ],
   "source": [
    "## Testing the resulting model\n",
    "print(model.evaluate(X, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the model for future use\n",
    "model.save('Mogilko.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
